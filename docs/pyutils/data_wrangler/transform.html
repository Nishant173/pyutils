<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pyutils.data_wrangler.transform API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pyutils.data_wrangler.transform</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from typing import Any, Callable, Dict, List, Optional, Union
from collections import Counter
from functools import reduce
import random

import numpy as np
import pandas as pd

from pyutils.core.date_ops import get_current_timestamp_as_integer
from pyutils.core.text_casing import (
    camel_to_pascal,
    camel_to_snake,
    pascal_to_camel,
    pascal_to_snake,
    snake_to_camel,
    snake_to_pascal,
)
from pyutils.core.type_annotations import (
    Number,
    NumberOrString,
)
from pyutils.core.utils import (
    get_partition_index_ranges,
    get_partition_lengths,
)


def get_mapping_between_columns(
        data: pd.DataFrame,
        from_: NumberOrString,
        to: NumberOrString,
    ) -&gt; Dict:
    &#34;&#34;&#34;Returns dictionary having mappings between the `from_` and `to` columns of the given DataFrame&#34;&#34;&#34;
    from_column_has_nulls = (data[from_].isnull().sum() &gt; 0)
    from_column_has_unique_values = (data[from_].nunique() == len(data))
    if from_column_has_nulls:
        raise ValueError(&#34;Values in the `from_` column must be non-nulls&#34;)
    if not from_column_has_unique_values:
        raise ValueError(&#34;Values in the `from_` column must be unique, as they will be the keys of the returned dictionary&#34;)
    mapper_dictionary = data.loc[:, [from_, to]].set_index(keys=[from_]).to_dict()[to]
    return mapper_dictionary


def spread_array_by_factor(
        array: List[Number],
        factor: int,
    ) -&gt; List[Number]:
    &#34;&#34;&#34;
    Spread out an array by given factor.
    &gt;&gt;&gt; spread_array_by_factor(array=[4, 6, 7, 3], factor=3)
    &gt;&gt;&gt; [4, 4, 4, 6, 6, 6, 7, 7, 7, 3, 3, 3]
    &#34;&#34;&#34;
    array_after_spreading = []
    for idx, _ in enumerate(array):
        array_after_spreading += [array[idx]] * int(factor)
    return array_after_spreading


def spread_array_by_length(
        array: List[Number],
        to: int,
    ) -&gt; List[Number]:
    &#34;&#34;&#34;
    Definition:
        Spread out an array to particular length without distorting signal of the original data.
    Parameters:
        - array (list): List or list-like array data
        - to (int): Length of array to be spread into
    &gt;&gt;&gt; spread_array_by_length(array=[2, 3, -7], to=14)
    &gt;&gt;&gt; [2, 2, 2, 2, 3, 3, 3, 3, 3, -7, -7, -7, -7, -7]
    &#34;&#34;&#34;
    initial_array_length = len(array)
    if initial_array_length &gt;= to:
        return array
    array_after_spread = []
    spread_factor = to / initial_array_length
    # If length of array to spread into is divisible by length of initial array
    if int(spread_factor) == spread_factor:
        array_after_spread = spread_array_by_factor(array=array, factor=int(spread_factor))
        return array_after_spread
    # Perform necessary complete fill-ups of the array to spread into
    num_complete_fillups = int(np.floor(spread_factor))
    if num_complete_fillups &gt; 0:
        array_after_spread = spread_array_by_factor(array=array, factor=num_complete_fillups)
    # Fill-up the remaining elements of `array_after_spread` randomly (to minimise distortion)
    while len(array_after_spread) != to:
        random_index = random.randint(0, len(array_after_spread)-1)
        random_element = array_after_spread[random_index]
        array_after_spread.insert(random_index+1, random_element)
    return array_after_spread


def linspace_by_index(
        array: List[Any],
        how_many: int,
    ) -&gt; List[Any]:
    &#34;&#34;&#34;
    Gets linspaced values from array (based on indices of the array).
    &gt;&gt;&gt; array = [0, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96]
    &gt;&gt;&gt; linspace_by_index(array=array, how_many=4) # Returns [0, 32, 64, 96]
    &gt;&gt;&gt; linspace_by_index(array=array, how_many=5) # Returns [0, 24, 48, 72, 96]
    &#34;&#34;&#34;
    linspaced_indices = list(np.linspace(start=0, stop=len(array) - 1, num=how_many))
    linspaced_indices = list(map(np.ceil, linspaced_indices))
    linspaced_indices = list(map(int, linspaced_indices))
    linspaced_values = [array[idx] for idx in linspaced_indices]
    return linspaced_values


def normalize_array(array: List[Number]) -&gt; List[Number]:
    &#34;&#34;&#34;
    Normalizes values in array to range of [0, 1].
    Ignores and removes all NaNs.
    &#34;&#34;&#34;
    array = np.array(array)
    array = array[~np.isnan(array)]
    normalized_array = (array - np.min(array)) / np.ptp(array)
    return list(normalized_array)


def dataframe_to_list(data: pd.DataFrame) -&gt; Union[List[Dict], List]:
    &#34;&#34;&#34;Converts DataFrame to a list of dictionaries&#34;&#34;&#34;
    if data.empty:
        return []
    return data.to_dict(orient=&#39;records&#39;)


def stringify_columns(data: pd.DataFrame) -&gt; pd.DataFrame:
    &#34;&#34;&#34;Converts all column names of the given DataFrame to strings (in case some of them are int/float)&#34;&#34;&#34;
    df = data.copy(deep=True)
    df.columns = list(map(str, df.columns.tolist()))
    return df


def merge_dataframes(
        dataframes: List[pd.DataFrame],
        how: str,
        on: List[NumberOrString],
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Merges list of DataFrames given.
    Parameters:
        - dataframes (list): List of DataFrames to merge.
        - how (str): The type of merge. Options: [&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;, &#39;cross&#39;]
        - on (list): List of columns to merge on.
    &#34;&#34;&#34;
    df_merged = reduce(
        lambda df_left, df_right: pd.merge(
            left=df_left,
            right=df_right,
            how=how,
            on=on,
        ),
        dataframes,
    )
    return df_merged


def drop_columns_if_exists(
        data: pd.DataFrame,
        columns: List[NumberOrString],
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;Drops list of given columns if they exist in the given DataFrame&#34;&#34;&#34;
    df = data.copy(deep=True)
    columns_available = df.columns.tolist()
    columns_to_drop = list(
        set(columns_available).intersection(set(columns))
    )
    if columns_to_drop:
        df.drop(labels=columns_to_drop, axis=1, inplace=True)
    return df


def transform_datetime_columns(
        data: pd.DataFrame,
        func: Callable,
        subset: Optional[List[NumberOrString]] = None,
        column_prefix: Optional[str] = &#39;&#39;,
        column_suffix: Optional[str] = &#39;&#39;,
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Takes in a DataFrame, and applies the given function to all &#39;datetime64&#39; columns in the DataFrame.
    Parameters:
        - data (DataFrame): Pandas DataFrame
        - func (callable): Callable Python function
        - subset (list): Subset of &#39;datetime64&#39; columns to apply the function to (optional)
        - column_prefix (str): Prefix to add to column name, if you want to create new columns (optional)
        - column_suffix (str): Suffix to add to column name, if you want to create new columns (optional)
    &#34;&#34;&#34;
    df = data.copy(deep=True)
    if subset:
        for column in subset:
            new_column = f&#34;{column_prefix}{column}{column_suffix}&#34;
            df[new_column] = df[column].apply(func=func)
    else:
        columns_with_datetimes = data.select_dtypes(include=[&#39;datetime64&#39;]).columns.tolist()
        for column in columns_with_datetimes:
            new_column = f&#34;{column_prefix}{column}{column_suffix}&#34;
            df[new_column] = df[column].apply(func=func)
    return df


def prettify_datetime_columns(
        data: pd.DataFrame,
        include_time: bool,
        subset: Optional[List[NumberOrString]] = None,
        column_prefix: Optional[str] = &#39;&#39;,
        column_suffix: Optional[str] = &#39;&#39;,
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Takes in Pandas DataFrame, and converts all &#39;datetime64&#39; columns to a more human readable format.
    Parameters:
        - data (DataFrame): Pandas DataFrame
        - include_time (bool): Includes time element if set to True
        - subset (list): Subset of datetime columns to prettify (optional)
        - column_prefix (str): Prefix to add to column name, if you want to create new columns (optional)
        - column_suffix (str): Suffix to add to column name, if you want to create new columns (optional)
    &#34;&#34;&#34;
    df = data.copy(deep=True)
    formatter = &#34;%d %B, %Y %I:%M %p&#34; if include_time else &#34;%d %B, %Y&#34;
    df = transform_datetime_columns(
        data=df,
        func=lambda dt_obj: dt_obj.strftime(formatter),
        subset=subset,
        column_prefix=column_prefix,
        column_suffix=column_suffix,
    )
    return df


def add_partitioning_column(
        data: pd.DataFrame,
        num_partitions: int,
        column_name: str,
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Partitions a DataFrame horizontally, based on number of partitions given.
    Returns DataFrame with an additional column containing the partition number.
    &#34;&#34;&#34;
    df = data.copy(deep=True)
    partition_lengths = get_partition_lengths(
        length_of_iterable=len(df),
        num_partitions=num_partitions,
    )
    partition_column_values = []
    for idx, partition_length in enumerate(partition_lengths):
        partition_number = idx + 1
        partition_column_values.extend([partition_number] * partition_length)
    df[column_name] = partition_column_values
    return df


def partition_dataframe_by_num_partitions(
        data: pd.DataFrame,
        num_partitions: int,
    ) -&gt; List[pd.DataFrame]:
    &#34;&#34;&#34;
    Partitions a DataFrame horizontally, based on number of partitions given.
    Returns list of partitioned DataFrames.
    &#34;&#34;&#34;
    df = data.copy(deep=True)
    partition_index_ranges = get_partition_index_ranges(
        length_of_iterable=len(df),
        num_partitions=num_partitions,
    )
    return [df.iloc[idx_start : idx_end] for idx_start, idx_end in partition_index_ranges]


def partition_dataframe_by_max_partition_length(
        data: pd.DataFrame,
        max_partition_length: int,
    ) -&gt; List[pd.DataFrame]:
    &#34;&#34;&#34;
    Partitions a DataFrame horizontally, based on maximum partition length given.
    Returns list of partitioned DataFrames.
    &#34;&#34;&#34;
    num_partitions = int(np.ceil(len(data) / max_partition_length))
    return partition_dataframe_by_num_partitions(data=data, num_partitions=num_partitions)


def switch_column_casing(
        data: pd.DataFrame,
        casing_type: str,
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Switch casing of columns in DataFrame.
    Options for `casing_type`:
        * &#39;camel_to_pascal&#39;: Converts camel-case to pascal-case (Eg: someText --&gt; SomeText)
        * &#39;camel_to_snake&#39;: Converts camel-case to snake-case (Eg: someText --&gt; some_text)
        * &#39;pascal_to_camel&#39;: Converts pascal-case to camel-case (Eg: SomeText --&gt; someText)
        * &#39;pascal_to_snake&#39;: Converts pascal-case to snake-case (Eg: SomeText --&gt; some_text)
        * &#39;snake_to_camel&#39;: Converts snake-case to camel-case (Eg: some_text --&gt; someText)
        * &#39;snake_to_pascal&#39;: Converts snake-case to pascal-case (Eg: some_text --&gt; SomeText)
    
    Note: Expects all columns present in DataFrame to be of same casing.
    &#34;&#34;&#34;
    df = data.copy(deep=True)
    mapper = {
        &#39;camel_to_pascal&#39;: camel_to_pascal,
        &#39;camel_to_snake&#39;: camel_to_snake,
        &#39;pascal_to_camel&#39;: pascal_to_camel,
        &#39;pascal_to_snake&#39;: pascal_to_snake,
        &#39;snake_to_camel&#39;: snake_to_camel,
        &#39;snake_to_pascal&#39;: snake_to_pascal,
    }
    columns = df.columns.tolist()
    df.columns = list(map(mapper[casing_type], columns))
    return df


def round_off_columns(
        data: pd.DataFrame,
        columns: List[NumberOrString],
        round_by: int,
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Rounds off specified numerical (float) columns in DataFrame.
    &gt;&gt;&gt; round_off_columns(data=data, columns=[&#39;column1&#39;, &#39;column3&#39;, &#39;column5&#39;], round_by=2)
    &#34;&#34;&#34;
    df = data.copy(deep=True)
    for column in columns:
        df[column] = df[column].apply(round, args=[int(round_by)])
    return df


def __get_row_number_rankings(df_ranked: pd.DataFrame) -&gt; List[int]:
    row_number_rankings = list(
        np.arange(start=1, stop=len(df_ranked) + 1, step=1)
    )
    return row_number_rankings


def __get_dense_rankings(
        df_ranked: pd.DataFrame,
        rank_by: List[NumberOrString],
    ) -&gt; List[int]:
    dense_rankings = [1]
    values_used_for_ranking = list(df_ranked[rank_by].itertuples(index=False))
    prev = values_used_for_ranking[0]
    for value in values_used_for_ranking[1:]:
        latest_rank_assigned = dense_rankings[-1]
        ranking_for_row = latest_rank_assigned if prev == value else latest_rank_assigned + 1
        dense_rankings.append(ranking_for_row)
        prev = value
    return dense_rankings


def __get_non_dense_rankings(
        df_ranked: pd.DataFrame,
        rank_by: List[NumberOrString],
    ) -&gt; List[int]:
    non_dense_rankings = [1]
    values_used_for_ranking = list(df_ranked[rank_by].itertuples(index=False))
    prev = values_used_for_ranking[0]
    for value in values_used_for_ranking[1:]:
        latest_rank_assigned = non_dense_rankings[-1]
        ranking_for_row = latest_rank_assigned if prev == value else latest_rank_assigned + Counter(non_dense_rankings)[latest_rank_assigned]
        non_dense_rankings.append(ranking_for_row)
        prev = value
    return non_dense_rankings


def rank_and_sort(
        data: pd.DataFrame,
        rank_column_name: NumberOrString,
        rank_by: List[NumberOrString],
        ascending: List[bool],
        how: str,
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Adds ranking column and sorts records based on the `rank_by` column/s.

    Parameters:
        - data (DataFrame): Pandas DataFrame.
        - rank_column_name (int | float | str): Name of the ranking column (the column which will contain the actual ranking).
        - rank_by (list): List of columns to rank by.
        - ascending (list): List of booleans signifying the order of ranking (must correspond to the columns in `rank_by`).
        - how (str): How the ranking should be implemented. Options: [&#39;row_number&#39;, &#39;dense_rank&#39;, &#39;non_dense_rank&#39;].
    
    |    | column   |   row_number |   dense_rank |   non_dense_rank |
    |---:|:---------|-------------:|-------------:|-----------------:|
    |  0 | a        |            1 |            1 |                1 |
    |  1 | a        |            2 |            1 |                1 |
    |  2 | a        |            3 |            1 |                1 |
    |  3 | a        |            4 |            1 |                1 |
    |  4 | b        |            5 |            2 |                5 |
    |  5 | b        |            6 |            2 |                5 |
    |  6 | c        |            7 |            3 |                7 |
    |  7 | d        |            8 |            4 |                8 |
    |  8 | d        |            9 |            4 |                8 |
    |  9 | e        |           10 |            5 |               10 |
    | 10 | e        |           11 |            5 |               10 |
    | 11 | f        |           12 |            6 |               12 |
    | 12 | g        |           13 |            7 |               13 |
    | 13 | g        |           14 |            7 |               13 |
    &#34;&#34;&#34;
    how_options = [&#39;row_number&#39;, &#39;dense_rank&#39;, &#39;non_dense_rank&#39;]
    if how not in how_options:
        raise ValueError(f&#34;Expected `how` to be in {how_options}, but got &#39;{how}&#39;&#34;)
    if len(rank_by) != len(ascending):
        raise ValueError(
            &#34;Expected `rank_by` and `ascending` to be of same length,&#34;
            f&#34; but got lengths {len(rank_by)} and {len(ascending)} respectively.&#34;
        )
    df_ranked = data.sort_values(by=rank_by, ascending=ascending, ignore_index=True).copy(deep=True)
    if how == &#39;row_number&#39;:
        rankings = __get_row_number_rankings(df_ranked=df_ranked)
    elif how == &#39;dense_rank&#39;:
        rankings = __get_dense_rankings(df_ranked=df_ranked, rank_by=rank_by)
    elif how == &#39;non_dense_rank&#39;:
        rankings = __get_non_dense_rankings(df_ranked=df_ranked, rank_by=rank_by)
    df_ranked[rank_column_name] = rankings
    column_order = [rank_column_name] + df_ranked.drop(labels=[rank_column_name], axis=1).columns.tolist()
    df_ranked = df_ranked.loc[:, column_order]
    return df_ranked


def normalize_numerical_columns(
        data: pd.DataFrame,
        columns: List[NumberOrString],
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Takes in DataFrame and list of numerical columns to normalize.
    Normalizes the given columns between [0-100].
    Note: Does not work with NaN values.
    &#34;&#34;&#34;
    df = data.copy(deep=True)
    for column in columns:
        values = df[column].tolist()
        df[column] = normalize_array(array=values)
        df[column] = df[column].mul(100).round(2)
    return df


def randomly_fill_categorical_nans(
        data: pd.DataFrame,
        subset: Optional[List[NumberOrString]] = None,
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Fills missing values of categorical columns by selecting random value from said column.
    Parameters:
        - data (DataFrame): Pandas DataFrame
        - subset (list): Subset of categorical columns for which you want to randomly fill missing values (optional)
    &#34;&#34;&#34;
    df = data.copy(deep=True)
    categorical_variables = df.select_dtypes(include=&#39;object&#39;).columns.tolist()
    if subset:
        categorical_variables = list(set(categorical_variables).intersection(set(subset)))
    null_indicator_string = f&#34;NULL-{get_current_timestamp_as_integer()}-{random.randint(1000, 9999)}&#34;
    for cv in categorical_variables:
        if df[cv].isnull().sum() &gt; 0:
            df[cv].fillna(value=null_indicator_string, inplace=True)
            unique_choices = df[cv].unique().tolist()
            unique_choices.remove(null_indicator_string)
            df[cv] = df[cv].apply(
                lambda string: random.choice(unique_choices) if ((string == null_indicator_string) and unique_choices) else string
            )
    return df</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pyutils.data_wrangler.transform.add_partitioning_column"><code class="name flex">
<span>def <span class="ident">add_partitioning_column</span></span>(<span>data: pandas.core.frame.DataFrame, num_partitions: int, column_name: str) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Partitions a DataFrame horizontally, based on number of partitions given.
Returns DataFrame with an additional column containing the partition number.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_partitioning_column(
        data: pd.DataFrame,
        num_partitions: int,
        column_name: str,
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Partitions a DataFrame horizontally, based on number of partitions given.
    Returns DataFrame with an additional column containing the partition number.
    &#34;&#34;&#34;
    df = data.copy(deep=True)
    partition_lengths = get_partition_lengths(
        length_of_iterable=len(df),
        num_partitions=num_partitions,
    )
    partition_column_values = []
    for idx, partition_length in enumerate(partition_lengths):
        partition_number = idx + 1
        partition_column_values.extend([partition_number] * partition_length)
    df[column_name] = partition_column_values
    return df</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.dataframe_to_list"><code class="name flex">
<span>def <span class="ident">dataframe_to_list</span></span>(<span>data: pandas.core.frame.DataFrame) ‑> List</span>
</code></dt>
<dd>
<div class="desc"><p>Converts DataFrame to a list of dictionaries</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dataframe_to_list(data: pd.DataFrame) -&gt; Union[List[Dict], List]:
    &#34;&#34;&#34;Converts DataFrame to a list of dictionaries&#34;&#34;&#34;
    if data.empty:
        return []
    return data.to_dict(orient=&#39;records&#39;)</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.drop_columns_if_exists"><code class="name flex">
<span>def <span class="ident">drop_columns_if_exists</span></span>(<span>data: pandas.core.frame.DataFrame, columns: List[Union[int, float, str]]) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Drops list of given columns if they exist in the given DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def drop_columns_if_exists(
        data: pd.DataFrame,
        columns: List[NumberOrString],
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;Drops list of given columns if they exist in the given DataFrame&#34;&#34;&#34;
    df = data.copy(deep=True)
    columns_available = df.columns.tolist()
    columns_to_drop = list(
        set(columns_available).intersection(set(columns))
    )
    if columns_to_drop:
        df.drop(labels=columns_to_drop, axis=1, inplace=True)
    return df</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.get_mapping_between_columns"><code class="name flex">
<span>def <span class="ident">get_mapping_between_columns</span></span>(<span>data: pandas.core.frame.DataFrame, from_: Union[int, float, str], to: Union[int, float, str]) ‑> Dict</span>
</code></dt>
<dd>
<div class="desc"><p>Returns dictionary having mappings between the <code>from_</code> and <code>to</code> columns of the given DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_mapping_between_columns(
        data: pd.DataFrame,
        from_: NumberOrString,
        to: NumberOrString,
    ) -&gt; Dict:
    &#34;&#34;&#34;Returns dictionary having mappings between the `from_` and `to` columns of the given DataFrame&#34;&#34;&#34;
    from_column_has_nulls = (data[from_].isnull().sum() &gt; 0)
    from_column_has_unique_values = (data[from_].nunique() == len(data))
    if from_column_has_nulls:
        raise ValueError(&#34;Values in the `from_` column must be non-nulls&#34;)
    if not from_column_has_unique_values:
        raise ValueError(&#34;Values in the `from_` column must be unique, as they will be the keys of the returned dictionary&#34;)
    mapper_dictionary = data.loc[:, [from_, to]].set_index(keys=[from_]).to_dict()[to]
    return mapper_dictionary</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.linspace_by_index"><code class="name flex">
<span>def <span class="ident">linspace_by_index</span></span>(<span>array: List[Any], how_many: int) ‑> List[Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Gets linspaced values from array (based on indices of the array).</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; array = [0, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96]
&gt;&gt;&gt; linspace_by_index(array=array, how_many=4) # Returns [0, 32, 64, 96]
&gt;&gt;&gt; linspace_by_index(array=array, how_many=5) # Returns [0, 24, 48, 72, 96]
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def linspace_by_index(
        array: List[Any],
        how_many: int,
    ) -&gt; List[Any]:
    &#34;&#34;&#34;
    Gets linspaced values from array (based on indices of the array).
    &gt;&gt;&gt; array = [0, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96]
    &gt;&gt;&gt; linspace_by_index(array=array, how_many=4) # Returns [0, 32, 64, 96]
    &gt;&gt;&gt; linspace_by_index(array=array, how_many=5) # Returns [0, 24, 48, 72, 96]
    &#34;&#34;&#34;
    linspaced_indices = list(np.linspace(start=0, stop=len(array) - 1, num=how_many))
    linspaced_indices = list(map(np.ceil, linspaced_indices))
    linspaced_indices = list(map(int, linspaced_indices))
    linspaced_values = [array[idx] for idx in linspaced_indices]
    return linspaced_values</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.merge_dataframes"><code class="name flex">
<span>def <span class="ident">merge_dataframes</span></span>(<span>dataframes: List[pandas.core.frame.DataFrame], how: str, on: List[Union[int, float, str]]) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Merges list of DataFrames given.</p>
<h2 id="parameters">Parameters</h2>
<ul>
<li>dataframes (list): List of DataFrames to merge.</li>
<li>how (str): The type of merge. Options: ['left', 'right', 'outer', 'inner', 'cross']</li>
<li>on (list): List of columns to merge on.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge_dataframes(
        dataframes: List[pd.DataFrame],
        how: str,
        on: List[NumberOrString],
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Merges list of DataFrames given.
    Parameters:
        - dataframes (list): List of DataFrames to merge.
        - how (str): The type of merge. Options: [&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;, &#39;cross&#39;]
        - on (list): List of columns to merge on.
    &#34;&#34;&#34;
    df_merged = reduce(
        lambda df_left, df_right: pd.merge(
            left=df_left,
            right=df_right,
            how=how,
            on=on,
        ),
        dataframes,
    )
    return df_merged</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.normalize_array"><code class="name flex">
<span>def <span class="ident">normalize_array</span></span>(<span>array: List[Union[int, float]]) ‑> List[Union[int, float]]</span>
</code></dt>
<dd>
<div class="desc"><p>Normalizes values in array to range of [0, 1].
Ignores and removes all NaNs.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def normalize_array(array: List[Number]) -&gt; List[Number]:
    &#34;&#34;&#34;
    Normalizes values in array to range of [0, 1].
    Ignores and removes all NaNs.
    &#34;&#34;&#34;
    array = np.array(array)
    array = array[~np.isnan(array)]
    normalized_array = (array - np.min(array)) / np.ptp(array)
    return list(normalized_array)</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.normalize_numerical_columns"><code class="name flex">
<span>def <span class="ident">normalize_numerical_columns</span></span>(<span>data: pandas.core.frame.DataFrame, columns: List[Union[int, float, str]]) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Takes in DataFrame and list of numerical columns to normalize.
Normalizes the given columns between [0-100].
Note: Does not work with NaN values.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def normalize_numerical_columns(
        data: pd.DataFrame,
        columns: List[NumberOrString],
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Takes in DataFrame and list of numerical columns to normalize.
    Normalizes the given columns between [0-100].
    Note: Does not work with NaN values.
    &#34;&#34;&#34;
    df = data.copy(deep=True)
    for column in columns:
        values = df[column].tolist()
        df[column] = normalize_array(array=values)
        df[column] = df[column].mul(100).round(2)
    return df</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.partition_dataframe_by_max_partition_length"><code class="name flex">
<span>def <span class="ident">partition_dataframe_by_max_partition_length</span></span>(<span>data: pandas.core.frame.DataFrame, max_partition_length: int) ‑> List[pandas.core.frame.DataFrame]</span>
</code></dt>
<dd>
<div class="desc"><p>Partitions a DataFrame horizontally, based on maximum partition length given.
Returns list of partitioned DataFrames.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def partition_dataframe_by_max_partition_length(
        data: pd.DataFrame,
        max_partition_length: int,
    ) -&gt; List[pd.DataFrame]:
    &#34;&#34;&#34;
    Partitions a DataFrame horizontally, based on maximum partition length given.
    Returns list of partitioned DataFrames.
    &#34;&#34;&#34;
    num_partitions = int(np.ceil(len(data) / max_partition_length))
    return partition_dataframe_by_num_partitions(data=data, num_partitions=num_partitions)</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.partition_dataframe_by_num_partitions"><code class="name flex">
<span>def <span class="ident">partition_dataframe_by_num_partitions</span></span>(<span>data: pandas.core.frame.DataFrame, num_partitions: int) ‑> List[pandas.core.frame.DataFrame]</span>
</code></dt>
<dd>
<div class="desc"><p>Partitions a DataFrame horizontally, based on number of partitions given.
Returns list of partitioned DataFrames.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def partition_dataframe_by_num_partitions(
        data: pd.DataFrame,
        num_partitions: int,
    ) -&gt; List[pd.DataFrame]:
    &#34;&#34;&#34;
    Partitions a DataFrame horizontally, based on number of partitions given.
    Returns list of partitioned DataFrames.
    &#34;&#34;&#34;
    df = data.copy(deep=True)
    partition_index_ranges = get_partition_index_ranges(
        length_of_iterable=len(df),
        num_partitions=num_partitions,
    )
    return [df.iloc[idx_start : idx_end] for idx_start, idx_end in partition_index_ranges]</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.prettify_datetime_columns"><code class="name flex">
<span>def <span class="ident">prettify_datetime_columns</span></span>(<span>data: pandas.core.frame.DataFrame, include_time: bool, subset: Optional[List[Union[int, float, str]]] = None, column_prefix: Optional[str] = '', column_suffix: Optional[str] = '') ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Takes in Pandas DataFrame, and converts all 'datetime64' columns to a more human readable format.</p>
<h2 id="parameters">Parameters</h2>
<ul>
<li>data (DataFrame): Pandas DataFrame</li>
<li>include_time (bool): Includes time element if set to True</li>
<li>subset (list): Subset of datetime columns to prettify (optional)</li>
<li>column_prefix (str): Prefix to add to column name, if you want to create new columns (optional)</li>
<li>column_suffix (str): Suffix to add to column name, if you want to create new columns (optional)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prettify_datetime_columns(
        data: pd.DataFrame,
        include_time: bool,
        subset: Optional[List[NumberOrString]] = None,
        column_prefix: Optional[str] = &#39;&#39;,
        column_suffix: Optional[str] = &#39;&#39;,
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Takes in Pandas DataFrame, and converts all &#39;datetime64&#39; columns to a more human readable format.
    Parameters:
        - data (DataFrame): Pandas DataFrame
        - include_time (bool): Includes time element if set to True
        - subset (list): Subset of datetime columns to prettify (optional)
        - column_prefix (str): Prefix to add to column name, if you want to create new columns (optional)
        - column_suffix (str): Suffix to add to column name, if you want to create new columns (optional)
    &#34;&#34;&#34;
    df = data.copy(deep=True)
    formatter = &#34;%d %B, %Y %I:%M %p&#34; if include_time else &#34;%d %B, %Y&#34;
    df = transform_datetime_columns(
        data=df,
        func=lambda dt_obj: dt_obj.strftime(formatter),
        subset=subset,
        column_prefix=column_prefix,
        column_suffix=column_suffix,
    )
    return df</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.randomly_fill_categorical_nans"><code class="name flex">
<span>def <span class="ident">randomly_fill_categorical_nans</span></span>(<span>data: pandas.core.frame.DataFrame, subset: Optional[List[Union[int, float, str]]] = None) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Fills missing values of categorical columns by selecting random value from said column.</p>
<h2 id="parameters">Parameters</h2>
<ul>
<li>data (DataFrame): Pandas DataFrame</li>
<li>subset (list): Subset of categorical columns for which you want to randomly fill missing values (optional)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def randomly_fill_categorical_nans(
        data: pd.DataFrame,
        subset: Optional[List[NumberOrString]] = None,
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Fills missing values of categorical columns by selecting random value from said column.
    Parameters:
        - data (DataFrame): Pandas DataFrame
        - subset (list): Subset of categorical columns for which you want to randomly fill missing values (optional)
    &#34;&#34;&#34;
    df = data.copy(deep=True)
    categorical_variables = df.select_dtypes(include=&#39;object&#39;).columns.tolist()
    if subset:
        categorical_variables = list(set(categorical_variables).intersection(set(subset)))
    null_indicator_string = f&#34;NULL-{get_current_timestamp_as_integer()}-{random.randint(1000, 9999)}&#34;
    for cv in categorical_variables:
        if df[cv].isnull().sum() &gt; 0:
            df[cv].fillna(value=null_indicator_string, inplace=True)
            unique_choices = df[cv].unique().tolist()
            unique_choices.remove(null_indicator_string)
            df[cv] = df[cv].apply(
                lambda string: random.choice(unique_choices) if ((string == null_indicator_string) and unique_choices) else string
            )
    return df</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.rank_and_sort"><code class="name flex">
<span>def <span class="ident">rank_and_sort</span></span>(<span>data: pandas.core.frame.DataFrame, rank_column_name: Union[int, float, str], rank_by: List[Union[int, float, str]], ascending: List[bool], how: str) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Adds ranking column and sorts records based on the <code>rank_by</code> column/s.</p>
<h2 id="parameters">Parameters</h2>
<ul>
<li>data (DataFrame): Pandas DataFrame.</li>
<li>rank_column_name (int | float | str): Name of the ranking column (the column which will contain the actual ranking).</li>
<li>rank_by (list): List of columns to rank by.</li>
<li>ascending (list): List of booleans signifying the order of ranking (must correspond to the columns in <code>rank_by</code>).</li>
<li>how (str): How the ranking should be implemented. Options: ['row_number', 'dense_rank', 'non_dense_rank'].</li>
</ul>
<table>
<thead>
<tr>
<th align="right"></th>
<th align="left">column</th>
<th align="right">row_number</th>
<th align="right">dense_rank</th>
<th align="right">non_dense_rank</th>
</tr>
</thead>
<tbody>
<tr>
<td align="right">0</td>
<td align="left">a</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr>
<td align="right">1</td>
<td align="left">a</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr>
<td align="right">2</td>
<td align="left">a</td>
<td align="right">3</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr>
<td align="right">3</td>
<td align="left">a</td>
<td align="right">4</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr>
<td align="right">4</td>
<td align="left">b</td>
<td align="right">5</td>
<td align="right">2</td>
<td align="right">5</td>
</tr>
<tr>
<td align="right">5</td>
<td align="left">b</td>
<td align="right">6</td>
<td align="right">2</td>
<td align="right">5</td>
</tr>
<tr>
<td align="right">6</td>
<td align="left">c</td>
<td align="right">7</td>
<td align="right">3</td>
<td align="right">7</td>
</tr>
<tr>
<td align="right">7</td>
<td align="left">d</td>
<td align="right">8</td>
<td align="right">4</td>
<td align="right">8</td>
</tr>
<tr>
<td align="right">8</td>
<td align="left">d</td>
<td align="right">9</td>
<td align="right">4</td>
<td align="right">8</td>
</tr>
<tr>
<td align="right">9</td>
<td align="left">e</td>
<td align="right">10</td>
<td align="right">5</td>
<td align="right">10</td>
</tr>
<tr>
<td align="right">10</td>
<td align="left">e</td>
<td align="right">11</td>
<td align="right">5</td>
<td align="right">10</td>
</tr>
<tr>
<td align="right">11</td>
<td align="left">f</td>
<td align="right">12</td>
<td align="right">6</td>
<td align="right">12</td>
</tr>
<tr>
<td align="right">12</td>
<td align="left">g</td>
<td align="right">13</td>
<td align="right">7</td>
<td align="right">13</td>
</tr>
<tr>
<td align="right">13</td>
<td align="left">g</td>
<td align="right">14</td>
<td align="right">7</td>
<td align="right">13</td>
</tr>
</tbody>
</table></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rank_and_sort(
        data: pd.DataFrame,
        rank_column_name: NumberOrString,
        rank_by: List[NumberOrString],
        ascending: List[bool],
        how: str,
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Adds ranking column and sorts records based on the `rank_by` column/s.

    Parameters:
        - data (DataFrame): Pandas DataFrame.
        - rank_column_name (int | float | str): Name of the ranking column (the column which will contain the actual ranking).
        - rank_by (list): List of columns to rank by.
        - ascending (list): List of booleans signifying the order of ranking (must correspond to the columns in `rank_by`).
        - how (str): How the ranking should be implemented. Options: [&#39;row_number&#39;, &#39;dense_rank&#39;, &#39;non_dense_rank&#39;].
    
    |    | column   |   row_number |   dense_rank |   non_dense_rank |
    |---:|:---------|-------------:|-------------:|-----------------:|
    |  0 | a        |            1 |            1 |                1 |
    |  1 | a        |            2 |            1 |                1 |
    |  2 | a        |            3 |            1 |                1 |
    |  3 | a        |            4 |            1 |                1 |
    |  4 | b        |            5 |            2 |                5 |
    |  5 | b        |            6 |            2 |                5 |
    |  6 | c        |            7 |            3 |                7 |
    |  7 | d        |            8 |            4 |                8 |
    |  8 | d        |            9 |            4 |                8 |
    |  9 | e        |           10 |            5 |               10 |
    | 10 | e        |           11 |            5 |               10 |
    | 11 | f        |           12 |            6 |               12 |
    | 12 | g        |           13 |            7 |               13 |
    | 13 | g        |           14 |            7 |               13 |
    &#34;&#34;&#34;
    how_options = [&#39;row_number&#39;, &#39;dense_rank&#39;, &#39;non_dense_rank&#39;]
    if how not in how_options:
        raise ValueError(f&#34;Expected `how` to be in {how_options}, but got &#39;{how}&#39;&#34;)
    if len(rank_by) != len(ascending):
        raise ValueError(
            &#34;Expected `rank_by` and `ascending` to be of same length,&#34;
            f&#34; but got lengths {len(rank_by)} and {len(ascending)} respectively.&#34;
        )
    df_ranked = data.sort_values(by=rank_by, ascending=ascending, ignore_index=True).copy(deep=True)
    if how == &#39;row_number&#39;:
        rankings = __get_row_number_rankings(df_ranked=df_ranked)
    elif how == &#39;dense_rank&#39;:
        rankings = __get_dense_rankings(df_ranked=df_ranked, rank_by=rank_by)
    elif how == &#39;non_dense_rank&#39;:
        rankings = __get_non_dense_rankings(df_ranked=df_ranked, rank_by=rank_by)
    df_ranked[rank_column_name] = rankings
    column_order = [rank_column_name] + df_ranked.drop(labels=[rank_column_name], axis=1).columns.tolist()
    df_ranked = df_ranked.loc[:, column_order]
    return df_ranked</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.round_off_columns"><code class="name flex">
<span>def <span class="ident">round_off_columns</span></span>(<span>data: pandas.core.frame.DataFrame, columns: List[Union[int, float, str]], round_by: int) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Rounds off specified numerical (float) columns in DataFrame.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; round_off_columns(data=data, columns=['column1', 'column3', 'column5'], round_by=2)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def round_off_columns(
        data: pd.DataFrame,
        columns: List[NumberOrString],
        round_by: int,
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Rounds off specified numerical (float) columns in DataFrame.
    &gt;&gt;&gt; round_off_columns(data=data, columns=[&#39;column1&#39;, &#39;column3&#39;, &#39;column5&#39;], round_by=2)
    &#34;&#34;&#34;
    df = data.copy(deep=True)
    for column in columns:
        df[column] = df[column].apply(round, args=[int(round_by)])
    return df</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.spread_array_by_factor"><code class="name flex">
<span>def <span class="ident">spread_array_by_factor</span></span>(<span>array: List[Union[int, float]], factor: int) ‑> List[Union[int, float]]</span>
</code></dt>
<dd>
<div class="desc"><p>Spread out an array by given factor.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; spread_array_by_factor(array=[4, 6, 7, 3], factor=3)
&gt;&gt;&gt; [4, 4, 4, 6, 6, 6, 7, 7, 7, 3, 3, 3]
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def spread_array_by_factor(
        array: List[Number],
        factor: int,
    ) -&gt; List[Number]:
    &#34;&#34;&#34;
    Spread out an array by given factor.
    &gt;&gt;&gt; spread_array_by_factor(array=[4, 6, 7, 3], factor=3)
    &gt;&gt;&gt; [4, 4, 4, 6, 6, 6, 7, 7, 7, 3, 3, 3]
    &#34;&#34;&#34;
    array_after_spreading = []
    for idx, _ in enumerate(array):
        array_after_spreading += [array[idx]] * int(factor)
    return array_after_spreading</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.spread_array_by_length"><code class="name flex">
<span>def <span class="ident">spread_array_by_length</span></span>(<span>array: List[Union[int, float]], to: int) ‑> List[Union[int, float]]</span>
</code></dt>
<dd>
<div class="desc"><h2 id="definition">Definition</h2>
<p>Spread out an array to particular length without distorting signal of the original data.</p>
<h2 id="parameters">Parameters</h2>
<ul>
<li>array (list): List or list-like array data</li>
<li>to (int): Length of array to be spread into</li>
</ul>
<pre><code class="language-python-repl">&gt;&gt;&gt; spread_array_by_length(array=[2, 3, -7], to=14)
&gt;&gt;&gt; [2, 2, 2, 2, 3, 3, 3, 3, 3, -7, -7, -7, -7, -7]
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def spread_array_by_length(
        array: List[Number],
        to: int,
    ) -&gt; List[Number]:
    &#34;&#34;&#34;
    Definition:
        Spread out an array to particular length without distorting signal of the original data.
    Parameters:
        - array (list): List or list-like array data
        - to (int): Length of array to be spread into
    &gt;&gt;&gt; spread_array_by_length(array=[2, 3, -7], to=14)
    &gt;&gt;&gt; [2, 2, 2, 2, 3, 3, 3, 3, 3, -7, -7, -7, -7, -7]
    &#34;&#34;&#34;
    initial_array_length = len(array)
    if initial_array_length &gt;= to:
        return array
    array_after_spread = []
    spread_factor = to / initial_array_length
    # If length of array to spread into is divisible by length of initial array
    if int(spread_factor) == spread_factor:
        array_after_spread = spread_array_by_factor(array=array, factor=int(spread_factor))
        return array_after_spread
    # Perform necessary complete fill-ups of the array to spread into
    num_complete_fillups = int(np.floor(spread_factor))
    if num_complete_fillups &gt; 0:
        array_after_spread = spread_array_by_factor(array=array, factor=num_complete_fillups)
    # Fill-up the remaining elements of `array_after_spread` randomly (to minimise distortion)
    while len(array_after_spread) != to:
        random_index = random.randint(0, len(array_after_spread)-1)
        random_element = array_after_spread[random_index]
        array_after_spread.insert(random_index+1, random_element)
    return array_after_spread</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.stringify_columns"><code class="name flex">
<span>def <span class="ident">stringify_columns</span></span>(<span>data: pandas.core.frame.DataFrame) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Converts all column names of the given DataFrame to strings (in case some of them are int/float)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stringify_columns(data: pd.DataFrame) -&gt; pd.DataFrame:
    &#34;&#34;&#34;Converts all column names of the given DataFrame to strings (in case some of them are int/float)&#34;&#34;&#34;
    df = data.copy(deep=True)
    df.columns = list(map(str, df.columns.tolist()))
    return df</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.switch_column_casing"><code class="name flex">
<span>def <span class="ident">switch_column_casing</span></span>(<span>data: pandas.core.frame.DataFrame, casing_type: str) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Switch casing of columns in DataFrame.
Options for <code>casing_type</code>:
* 'camel_to_pascal': Converts camel-case to pascal-case (Eg: someText &ndash;&gt; SomeText)
* 'camel_to_snake': Converts camel-case to snake-case (Eg: someText &ndash;&gt; some_text)
* 'pascal_to_camel': Converts pascal-case to camel-case (Eg: SomeText &ndash;&gt; someText)
* 'pascal_to_snake': Converts pascal-case to snake-case (Eg: SomeText &ndash;&gt; some_text)
* 'snake_to_camel': Converts snake-case to camel-case (Eg: some_text &ndash;&gt; someText)
* 'snake_to_pascal': Converts snake-case to pascal-case (Eg: some_text &ndash;&gt; SomeText)</p>
<p>Note: Expects all columns present in DataFrame to be of same casing.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def switch_column_casing(
        data: pd.DataFrame,
        casing_type: str,
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Switch casing of columns in DataFrame.
    Options for `casing_type`:
        * &#39;camel_to_pascal&#39;: Converts camel-case to pascal-case (Eg: someText --&gt; SomeText)
        * &#39;camel_to_snake&#39;: Converts camel-case to snake-case (Eg: someText --&gt; some_text)
        * &#39;pascal_to_camel&#39;: Converts pascal-case to camel-case (Eg: SomeText --&gt; someText)
        * &#39;pascal_to_snake&#39;: Converts pascal-case to snake-case (Eg: SomeText --&gt; some_text)
        * &#39;snake_to_camel&#39;: Converts snake-case to camel-case (Eg: some_text --&gt; someText)
        * &#39;snake_to_pascal&#39;: Converts snake-case to pascal-case (Eg: some_text --&gt; SomeText)
    
    Note: Expects all columns present in DataFrame to be of same casing.
    &#34;&#34;&#34;
    df = data.copy(deep=True)
    mapper = {
        &#39;camel_to_pascal&#39;: camel_to_pascal,
        &#39;camel_to_snake&#39;: camel_to_snake,
        &#39;pascal_to_camel&#39;: pascal_to_camel,
        &#39;pascal_to_snake&#39;: pascal_to_snake,
        &#39;snake_to_camel&#39;: snake_to_camel,
        &#39;snake_to_pascal&#39;: snake_to_pascal,
    }
    columns = df.columns.tolist()
    df.columns = list(map(mapper[casing_type], columns))
    return df</code></pre>
</details>
</dd>
<dt id="pyutils.data_wrangler.transform.transform_datetime_columns"><code class="name flex">
<span>def <span class="ident">transform_datetime_columns</span></span>(<span>data: pandas.core.frame.DataFrame, func: Callable, subset: Optional[List[Union[int, float, str]]] = None, column_prefix: Optional[str] = '', column_suffix: Optional[str] = '') ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Takes in a DataFrame, and applies the given function to all 'datetime64' columns in the DataFrame.</p>
<h2 id="parameters">Parameters</h2>
<ul>
<li>data (DataFrame): Pandas DataFrame</li>
<li>func (callable): Callable Python function</li>
<li>subset (list): Subset of 'datetime64' columns to apply the function to (optional)</li>
<li>column_prefix (str): Prefix to add to column name, if you want to create new columns (optional)</li>
<li>column_suffix (str): Suffix to add to column name, if you want to create new columns (optional)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform_datetime_columns(
        data: pd.DataFrame,
        func: Callable,
        subset: Optional[List[NumberOrString]] = None,
        column_prefix: Optional[str] = &#39;&#39;,
        column_suffix: Optional[str] = &#39;&#39;,
    ) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Takes in a DataFrame, and applies the given function to all &#39;datetime64&#39; columns in the DataFrame.
    Parameters:
        - data (DataFrame): Pandas DataFrame
        - func (callable): Callable Python function
        - subset (list): Subset of &#39;datetime64&#39; columns to apply the function to (optional)
        - column_prefix (str): Prefix to add to column name, if you want to create new columns (optional)
        - column_suffix (str): Suffix to add to column name, if you want to create new columns (optional)
    &#34;&#34;&#34;
    df = data.copy(deep=True)
    if subset:
        for column in subset:
            new_column = f&#34;{column_prefix}{column}{column_suffix}&#34;
            df[new_column] = df[column].apply(func=func)
    else:
        columns_with_datetimes = data.select_dtypes(include=[&#39;datetime64&#39;]).columns.tolist()
        for column in columns_with_datetimes:
            new_column = f&#34;{column_prefix}{column}{column_suffix}&#34;
            df[new_column] = df[column].apply(func=func)
    return df</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pyutils.data_wrangler" href="index.html">pyutils.data_wrangler</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pyutils.data_wrangler.transform.add_partitioning_column" href="#pyutils.data_wrangler.transform.add_partitioning_column">add_partitioning_column</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.dataframe_to_list" href="#pyutils.data_wrangler.transform.dataframe_to_list">dataframe_to_list</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.drop_columns_if_exists" href="#pyutils.data_wrangler.transform.drop_columns_if_exists">drop_columns_if_exists</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.get_mapping_between_columns" href="#pyutils.data_wrangler.transform.get_mapping_between_columns">get_mapping_between_columns</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.linspace_by_index" href="#pyutils.data_wrangler.transform.linspace_by_index">linspace_by_index</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.merge_dataframes" href="#pyutils.data_wrangler.transform.merge_dataframes">merge_dataframes</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.normalize_array" href="#pyutils.data_wrangler.transform.normalize_array">normalize_array</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.normalize_numerical_columns" href="#pyutils.data_wrangler.transform.normalize_numerical_columns">normalize_numerical_columns</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.partition_dataframe_by_max_partition_length" href="#pyutils.data_wrangler.transform.partition_dataframe_by_max_partition_length">partition_dataframe_by_max_partition_length</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.partition_dataframe_by_num_partitions" href="#pyutils.data_wrangler.transform.partition_dataframe_by_num_partitions">partition_dataframe_by_num_partitions</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.prettify_datetime_columns" href="#pyutils.data_wrangler.transform.prettify_datetime_columns">prettify_datetime_columns</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.randomly_fill_categorical_nans" href="#pyutils.data_wrangler.transform.randomly_fill_categorical_nans">randomly_fill_categorical_nans</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.rank_and_sort" href="#pyutils.data_wrangler.transform.rank_and_sort">rank_and_sort</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.round_off_columns" href="#pyutils.data_wrangler.transform.round_off_columns">round_off_columns</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.spread_array_by_factor" href="#pyutils.data_wrangler.transform.spread_array_by_factor">spread_array_by_factor</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.spread_array_by_length" href="#pyutils.data_wrangler.transform.spread_array_by_length">spread_array_by_length</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.stringify_columns" href="#pyutils.data_wrangler.transform.stringify_columns">stringify_columns</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.switch_column_casing" href="#pyutils.data_wrangler.transform.switch_column_casing">switch_column_casing</a></code></li>
<li><code><a title="pyutils.data_wrangler.transform.transform_datetime_columns" href="#pyutils.data_wrangler.transform.transform_datetime_columns">transform_datetime_columns</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>